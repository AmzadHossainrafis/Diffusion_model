{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train_config': {'train_name': 'diffusion unconditional', 'batch_size': 4, 'epochs': 500, 'lr': 0.0003, 'device': 'cuda', 'shaffle': True, 'intrable': 1, 'num_sample': 3, 'model_ckpt': '/home/amzad/Desktop/diffusion/artifacts/model_ckpt/', 'logs': '/home/amzad/Desktop/diffusion/logs/', 'figs': '/home/amzad/Desktop/diffusion/fig/', 'dataset': '/home/amzad/Desktop/diffusion/dataset/images/', 'ema_enable': True, 'ema': 0.999}, 'Noise_schedule': {'start': 0.0001, 'end': 0.02, 'steps': 1000, 'device': 'cuda'}, 'Dir': {'artifact_dir': '/home/amzad/Desktop/diffusion/artifacts'}, 'Transform_config': {'image_size': 64, 'resize': 80, 'crop': 64, 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'to_tensor': True}, 'model_config': {'cha_in': 3, 'cha_out': 3, 'time_dim': 256, 'device': 'cuda', 'selfattn': {'n_head': 4, 'batch_first': True}, 'dobule_conv': {'kernel_size': 3, 'stride': 1, 'padding': 1, 'bias': True}, 'down': {'kernel_size': 4, 'stride': 2, 'padding': 1, 'bias': False}}}\n"
     ]
    }
   ],
   "source": [
    "config_dir= '/home/amzad/Desktop/diffusion/config/config.yaml'\n",
    "from Diffusion.utils.utils import read_config\n",
    "\n",
    "\n",
    "\n",
    "config = read_config(config_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__file__ = '/home/amzad/Desktop/diffusion/config/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pathlib \n",
    "from pathlib import Path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amzad\n",
      "/home/amzad/Desktop/diffusion\n",
      "/home/amzad/Desktop/diffusion/config/config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(Path.home())\n",
    "print(Path.cwd().parents[0])\n",
    "print(Path.cwd().parents[0] / 'config' / 'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amzad/Desktop/diffusion/config/config.yaml\n"
     ]
    }
   ],
   "source": [
    "test_config = Path.cwd().parents[0] / 'config' / 'config.yaml'\n",
    "print(test_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = read_config(test_config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train_config': {'train_name': 'diffusion unconditional', 'batch_size': 4, 'epochs': 500, 'lr': 0.0003, 'device': 'cuda', 'shaffle': True, 'intrable': 1, 'num_sample': 3, 'model_ckpt': '/home/amzad/Desktop/diffusion/artifacts/model_ckpt/', 'logs': '/home/amzad/Desktop/diffusion/logs/', 'figs': '/home/amzad/Desktop/diffusion/fig/', 'dataset': '/home/amzad/Desktop/diffusion/dataset/images/', 'ema_enable': True, 'ema': 0.999}, 'Noise_schedule': {'start': 0.0001, 'end': 0.02, 'steps': 1000, 'device': 'cuda'}, 'Dir': {'artifact_dir': '/home/amzad/Desktop/diffusion/artifacts'}, 'Transform_config': {'image_size': 64, 'resize': 80, 'crop': 64, 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'to_tensor': True}, 'model_config': {'cha_in': 3, 'cha_out': 3, 'time_dim': 256, 'device': 'cuda', 'selfattn': {'n_head': 4, 'batch_first': True}, 'dobule_conv': {'kernel_size': 3, 'stride': 1, 'padding': 1, 'bias': True}, 'down': {'kernel_size': 4, 'stride': 2, 'padding': 1, 'bias': False}}}\n"
     ]
    }
   ],
   "source": [
    "print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     60\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[43mlpips\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(L) \n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 47\u001b[0m, in \u001b[0;36mLPIPS.forward\u001b[0;34m(self, in0, in1, normalize)\u001b[0m\n\u001b[1;32m     45\u001b[0m feats0, feats1, diffs \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m---> 47\u001b[0m     feats0\u001b[38;5;241m.\u001b[39mappend(F\u001b[38;5;241m.\u001b[39mnormalize(\u001b[43mouts0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     48\u001b[0m     feats1\u001b[38;5;241m.\u001b[39mappend(F\u001b[38;5;241m.\u001b[39mnormalize(outs1[layer\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     49\u001b[0m     diffs\u001b[38;5;241m.\u001b[39mappend((feats0[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m feats1[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "class ScalingLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScalingLayer, self).__init__()\n",
    "        self.register_buffer('shift', torch.Tensor([-.030, -.088, -.188])[None, :, None, None])\n",
    "        self.register_buffer('scale', torch.Tensor([.458, .448, .450])[None, :, None, None])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.shift) / self.scale\n",
    "\n",
    "class NetLinLayer(nn.Module):\n",
    "    def __init__(self, ch, use_dropout=True):\n",
    "        super(NetLinLayer, self).__init__()\n",
    "        layers = [nn.Conv2d(ch, 1, 1, 1, 0, bias=False)]\n",
    "        if use_dropout:\n",
    "            layers.append(nn.Dropout())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class LPIPS(nn.Module):\n",
    "    def __init__(self, net=\"vgg\", use_dropout=True):\n",
    "        super(LPIPS, self).__init__()\n",
    "        self.scaling_layer = ScalingLayer()\n",
    "        vgg = models.vgg16(pretrained=True).features\n",
    "        self.layers = [3, 8, 15, 22, 29]\n",
    "        self.vgg = nn.Sequential(*[vgg[i] for i in range(max(self.layers) + 1)])\n",
    "        self.lins = nn.ModuleList([NetLinLayer(ch, use_dropout=use_dropout) for ch in [64, 128, 256, 512, 512]])\n",
    "        self.eval()\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, in0, in1, normalize=False):\n",
    "        if normalize:\n",
    "            in0, in1 = 2 * in0 - 1, 2 * in1 - 1\n",
    "\n",
    "        in0_input, in1_input = self.scaling_layer(in0), self.scaling_layer(in1)\n",
    "        outs0, outs1 = self.vgg(in0_input), self.vgg(in1_input)\n",
    "        \n",
    "        feats0, feats1, diffs = [], [], []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            feats0.append(F.normalize(outs0[layer], dim=1))\n",
    "            feats1.append(F.normalize(outs1[layer-1], dim=1))\n",
    "            diffs.append((feats0[-1] - feats1[-1]) ** 2)\n",
    "\n",
    "        res = [F.adaptive_avg_pool2d(self.lins[i](diffs[i]), (1, 1)) for i in range(len(self.layers))]\n",
    "        return sum(res)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return F\"VGG16 with LPIPS loss {self.lins} layers and {self.vgg} features  \"\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lpips = LPIPS()\n",
    "    x = torch.randn(1, 3, 256, 256)\n",
    "    y = torch.randn(1, 3, 256, 256)\n",
    "    L = lpips(x, y) \n",
    "    print(L) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
